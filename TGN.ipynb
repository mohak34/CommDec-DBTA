{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58b6cc9",
   "metadata": {},
   "source": [
    "# Temporal Graph Networks (TGN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b28dc",
   "metadata": {},
   "source": [
    "This notebook focuses on the implementation and exploration of Temporal Graph Networks (TGN), a model for learning on dynamic graphs where the structure and features change over time.\n",
    "\n",
    "Code from : https://github.com/twitter-research/tgn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f78392",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc34a56",
   "metadata": {},
   "source": [
    "Ensure that PyTorch, PyTorch Geometric, and PyTorch Geometric Temporal are installed. If you've run the `PyTorchGeometicTemporal.ipynb` notebook, these should already be available in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34d6aa",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b865a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import TGNMemory, TransformerConv\n",
    "from torch_geometric.data import TemporalData\n",
    "import torch_geometric_temporal # To ensure it's accessible, version check optional here\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648e732",
   "metadata": {},
   "source": [
    "## 3. TGN Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b26b75",
   "metadata": {},
   "source": [
    "The TGN model consists of several key components:\n",
    "1. **Memory**: Stores an up-to-date representation of each node in the graph.\n",
    "2. **Message Function**: Computes messages from node interactions.\n",
    "3. **Message Aggregator**: Aggregates messages for a node.\n",
    "4. **Memory Updater**: Updates the node's memory based on aggregated messages.\n",
    "5. **Embedding Module**: Generates temporal embeddings for nodes, used for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGNModel(nn.Module):\n",
    "    def __init__(self, num_nodes, raw_msg_dim, memory_dim, time_dim, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.raw_msg_dim = raw_msg_dim\n",
    "        self.memory_dim = memory_dim\n",
    "        self.time_dim = time_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # TGN Memory module\n",
    "        self.memory = TGNMemory(\n",
    "            num_nodes=self.num_nodes,\n",
    "            raw_msg_dim=self.raw_msg_dim, # Dimension of raw messages (e.g., edge features)\n",
    "            memory_dim=self.memory_dim,   # Dimension of node memory\n",
    "            time_dim=self.time_dim,       # Dimension of time encoding\n",
    "            message_module=nn.Identity(), # Simple message function (can be more complex)\n",
    "            aggregator_module=nn.LSTM(input_size=self.memory_dim + self.time_dim + self.raw_msg_dim, # Example input size\n",
    "                                      hidden_size=self.memory_dim) # Example aggregator\n",
    "        )\n",
    "\n",
    "        # Graph attention layer for embeddings (example: TransformerConv)\n",
    "        # The input to this layer will be the node memory (or a projection of it)\n",
    "        self.gnn_conv = TransformerConv(in_channels=self.memory_dim, \n",
    "                                        out_channels=self.embedding_dim, \n",
    "                                        heads=2, \n",
    "                                        dropout=0.1)\n",
    "\n",
    "        # Link predictor (example for link prediction task)\n",
    "        self.link_pred = nn.Linear(self.embedding_dim * 2, 1)\n",
    "\n",
    "    def forward(self, n_id, t, msg, src, dst, edge_index=None):\n",
    "        # n_id: node ids involved in current batch/snapshot\n",
    "        # t: timestamps of events\n",
    "        # msg: raw messages (e.g., edge features)\n",
    "        # src, dst: source and destination nodes of events\n",
    "        # edge_index: if you have a static graph structure for the GNN part, otherwise derive from src/dst\n",
    "\n",
    "        # 1. Update/Query Memory\n",
    "        # Process recent events to update memory (for training)\n",
    "        # For inference/embedding generation, you might just query the memory\n",
    "        # The TGNMemory module handles this based on its internal state and input\n",
    "        # This is a simplified view; actual TGNMemory usage might be more involved\n",
    "        # For example, memory.update_state(src, dst, t, msg) might be called during training loops\n",
    "        # And memory.get_memory(n_id) to retrieve memory for embedding generation.\n",
    "\n",
    "        # Let's assume we get the latest memory for nodes in n_id\n",
    "        # This is a placeholder for how you'd interact with memory. The TGNMemory API is more nuanced.\n",
    "        # Typically, you'd call `memory.update_state` for new events and `memory.get_memory` for node states.\n",
    "        # For simplicity in this forward, let's assume `memory.memory` gives current node memories.\n",
    "        # This is NOT the direct API usage for TGNMemory, but for a conceptual model structure.\n",
    "        node_memory = self.memory.memory[n_id] # Placeholder access\n",
    "\n",
    "        # 2. Generate Embeddings using GNN\n",
    "        # If edge_index is not provided, it might need to be constructed from src, dst for the current batch\n",
    "        # This depends on whether the GNN operates on the full graph or a batch-specific subgraph\n",
    "        if edge_index is None:\n",
    "            # Create a simple edge_index for the batch if needed for the GNN layer\n",
    "            # This is a simplification. TGN often uses temporal sampling for GNN input.\n",
    "            # Map src, dst to 0...N-1 for the batch if they are global IDs\n",
    "            unique_nodes, batch_n_id = torch.unique(torch.cat([src, dst]), return_inverse=True)\n",
    "            batch_src, batch_dst = batch_n_id[:len(src)], batch_n_id[len(src):]\n",
    "            edge_index = torch.stack([batch_src, batch_dst], dim=0)\n",
    "            # And node_memory would need to correspond to these unique_nodes\n",
    "            # node_memory = self.memory.memory[unique_nodes] # More accurate placeholder\n",
    "\n",
    "        # The GNN conv expects node features and edge_index\n",
    "        # Here, node_memory serves as input features to the GNN\n",
    "        x = self.gnn_conv(node_memory, edge_index) # x will be node embeddings\n",
    "\n",
    "        # 3. Example: Link Prediction (if this is the task)\n",
    "        # This requires embeddings for source and destination nodes of potential links\n",
    "        # For the given src, dst, we need to map them to the GNN output `x`\n",
    "        # This part is highly dependent on how `x` (embeddings) aligns with `src` and `dst` (global IDs)\n",
    "        # Assuming `x` corresponds to `n_id` if `edge_index` was for the batch using `n_id` directly.\n",
    "        # Or if `x` corresponds to `unique_nodes` from the batch construction.\n",
    "\n",
    "        # For simplicity, let's assume x contains embeddings for all nodes in n_id\n",
    "        # and src/dst are indices relative to n_id or can be mapped.\n",
    "        # This is a conceptual step for link prediction:\n",
    "        # src_emb = x[src_indices_in_x]\n",
    "        # dst_emb = x[dst_indices_in_x]\n",
    "        # link_emb = torch.cat([src_emb, dst_emb], dim=1)\n",
    "        # pred = self.link_pred(link_emb)\n",
    "        # return pred, node_memory # Or just embeddings if that's the output\n",
    "\n",
    "        return x, node_memory # Return embeddings and memory (or just embeddings)\n",
    "\n",
    "    def reset_memory(self):\n",
    "        self.memory.reset_state() # Reset memory state (e.g., at the start of an epoch)\n",
    "\n",
    "    def detach_memory(self):\n",
    "        self.memory.detach() # Detach memory from computation graph (e.g., for BPTT)\n",
    "\n",
    "print(\"TGNModel class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1cd0f",
   "metadata": {},
   "source": [
    "### Example Usage (Conceptual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (example values)\n",
    "num_nodes = 100        # Total number of nodes in the graph\n",
    "raw_msg_dim = 16       # Dimension of raw edge features (messages)\n",
    "memory_dim = 32        # Dimension of the node memory\n",
    "time_dim = 8           # Dimension of the time encoding fed to memory\n",
    "embedding_dim = 64     # Dimension of the final node embeddings\n",
    "\n",
    "# Instantiate the model\n",
    "tgn_model = TGNModel(num_nodes, raw_msg_dim, memory_dim, time_dim, embedding_dim)\n",
    "print(\"TGNModel instantiated.\")\n",
    "\n",
    "# --- Conceptual Data for one batch/step ---\n",
    "# This data would typically come from a DataLoader handling TemporalData objects\n",
    "batch_size = 32 # Number of events in the batch\n",
    "\n",
    "# Node IDs involved in the current events (global IDs)\n",
    "src_nodes = torch.randint(0, num_nodes, (batch_size,))\n",
    "dst_nodes = torch.randint(0, num_nodes, (batch_size,))\n",
    "n_ids_batch = torch.cat([src_nodes, dst_nodes]).unique() # Unique nodes in this batch\n",
    "\n",
    "# Timestamps of events\n",
    "event_times = torch.rand(batch_size).sort().values * 100 # Sorted timestamps\n",
    "\n",
    "# Raw messages (edge features)\n",
    "edge_features = torch.randn(batch_size, raw_msg_dim)\n",
    "\n",
    "# --- Interacting with the TGNMemory (this happens typically during the training loop) ---\n",
    "# 1. Update memory with new events (for training). This modifies memory internal state.\n",
    "# `tgn_model.memory.update_state(src_nodes, dst_nodes, event_times, edge_features)`\n",
    "# Note: The `update_state` method of TGNMemory expects specific arguments and structure.\n",
    "# It typically involves raw messages, time encodings, etc.\n",
    "# The `message_module` and `aggregator_module` defined in TGNMemory are used here.\n",
    "\n",
    "# 2. Get current memory for nodes (e.g., for GNN input or final embeddings)\n",
    "# current_node_memories = tgn_model.memory.get_memory(n_ids_batch)\n",
    "# Or, if you want all memories: `tgn_model.memory.memory` (but use `get_memory` for specific nodes)\n",
    "\n",
    "# --- Forward pass (simplified for this example) ---\n",
    "# The forward pass in the TGNModel class is a bit conceptual.\n",
    "# A more complete TGN pipeline would involve:\n",
    "#   a. Processing a batch of events: update memory, compute messages.\n",
    "#   b. For nodes involved in these events (or a sampled neighborhood), generate embeddings using the GNN.\n",
    "#   c. Use these embeddings for a downstream task (e.g., link prediction, node classification).\n",
    "\n",
    "print(\"Conceptual data prepared. Note: Actual TGN training involves careful handling of memory updates and batching.\")\n",
    "\n",
    "# To actually run the forward pass as defined (which is conceptual):\n",
    "# output_embeddings, last_memory_state = tgn_model(n_ids_batch, event_times, edge_features, src_nodes, dst_nodes)\n",
    "# print(f\"Output embedding shape (conceptual): {output_embeddings.shape}\")\n",
    "# print(f\"Last memory state shape (conceptual): {last_memory_state.shape}\")\n",
    "\n",
    "# Reset memory (e.g., at the start of an epoch)\n",
    "# tgn_model.reset_memory()\n",
    "# print(\"Memory reset.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
