{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee8a23c6",
   "metadata": {},
   "source": [
    "# PyTorch Geometric Temporal for Dynamic Network Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c71c67",
   "metadata": {},
   "source": [
    "This notebook explores the implementation of PyTorch Geometric Temporal, focusing on its application in the research project: *Implementing Decay-Based Temporal Attention for Dynamic Network Adaptation*.\n",
    "\n",
    "Code from : https://github.com/benedekrozemberczki/pytorch_geometric_temporal "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0c59c",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation of required libraries\n",
    "# Ensure you have PyTorch installed. If not, uncomment and run the appropriate command from https://pytorch.org/get-started/locally/ and for CUDA enabled GPU support use cuda12.8\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "\n",
    "# Install PyTorch Geometric and PyTorch Geometric Temporal\n",
    "!pip install torch-geometric\n",
    "!pip install torch-geometric-temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6aa4ac",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric_temporal\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"PyTorch Geometric Temporal version: {torch_geometric_temporal.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7098aba",
   "metadata": {},
   "source": [
    "## 3. Implementing Decay-Based Temporal Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883c617",
   "metadata": {},
   "source": [
    "This section will focus on building and utilizing models from PyTorch Geometric Temporal, particularly those that can be adapted or extended for decay-based temporal attention mechanisms in dynamic networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c4836",
   "metadata": {},
   "source": [
    "### 3.1. Baseline Implementation: TGAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85865a59",
   "metadata": {},
   "source": [
    "We'll start by implementing a baseline model using PyTorch Geometric Temporal's Temporal Graph Attention Network (TGAT). We will then extend this model to incorporate a decay mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.nn.conv import TGATConv\n",
    "import torch\n",
    "\n",
    "class TGATWithDecay(TGATConv):\n",
    "    def __init__(self, in_channels, out_channels, heads=1, concat=True, negative_slope=0.2, dropout=0.0, bias=True, add_self_loops=True, improved=False, **kwargs):\n",
    "        super().__init__(in_channels=in_channels, out_channels=out_channels, heads=heads, concat=concat, negative_slope=negative_slope, dropout=dropout, bias=bias, add_self_loops=add_self_loops, improved=improved, **kwargs)\n",
    "        self.decay_rate = kwargs.get('decay_rate', 0.1) # Default decay_rate if not provided\n",
    "\n",
    "    def forward(self, x, edge_index, edge_time, size=None):\n",
    "        # Assuming x is a tuple (node_features, node_timestamps)\n",
    "        # Or that node_timestamps can be accessed/derived. \n",
    "        # For simplicity, let's assume node_timestamps are passed or accessible.\n",
    "        # This part needs careful handling based on how TGATConv expects inputs \n",
    "        # and how timestamps are managed in your specific dataset.\n",
    "\n",
    "        # Placeholder for time difference calculation - this needs to be adapted to your data\n",
    "        # For example, if x is (features, timestamps_tensor)\n",
    "        # node_timestamps = x[1] \n",
    "        # time_diff = edge_time - node_timestamps[edge_index[0]] # Time diff relative to source node of an edge\n",
    "        \n",
    "        # A more generic approach might involve passing timestamps separately or as part of x\n",
    "        # This is a conceptual placeholder for decay calculation:\n",
    "        # time_diff = ... # Calculate time differences based on your data structure\n",
    "        # decay = torch.exp(-self.decay_rate * time_diff)\n",
    "        \n",
    "        # The original TGATConv forward signature is (x, edge_index, edge_attr=None, size=None, return_attention_weights=None)\n",
    "        # We need to ensure our 'decay' can be used as 'edge_attr'.\n",
    "        # The structure of 'edge_attr' (decay) must match what TGATConv expects.\n",
    "        \n",
    "        # For now, let's call super().forward without edge_attr modification\n",
    "        # as the exact mechanism for integrating decay as edge_attr in TGATConv\n",
    "        # requires more details on data structure and TGATConv's internal workings.\n",
    "        # The user's original code `return super().forward(x, edge_index, edge_attr=decay)` \n",
    "        # implies that edge_attr can be directly used for this. We will follow that, \n",
    "        # but it's important to ensure `decay` has the correct shape and meaning.\n",
    "\n",
    "        # A simplified assumption: edge_time is a tensor of timestamps for each edge.\n",
    "        # And we need a base time for each node to calculate the difference.\n",
    "        # This is highly dependent on the dataset and how TGATConv is meant to be used.\n",
    "        # The original TGATConv does not explicitly use edge_time in its forward pass in this manner.\n",
    "        # The user's snippet `time_diff = edge_time - x.time` implies x has a .time attribute.\n",
    "        # Let's assume x is a structure or object that has a .time attribute (e.g., node timestamps)\n",
    "        # and edge_time is a tensor of timestamps for edges.\n",
    "\n",
    "        # This part is speculative based on the user's snippet and needs to be verified with actual data.\n",
    "        # If x is just a feature tensor, x.time will not work.\n",
    "        # For demonstration, let's assume x is a feature tensor and we'll need another way to get node times.\n",
    "        # Or, if edge_time itself represents the time differences, then decay can be computed directly.\n",
    "\n",
    "        # Given the user's snippet: `time_diff = edge_time - x.time`\n",
    "        # This implies `x` is not just the feature matrix but might be a custom object or tuple\n",
    "        # where `x.time` refers to the timestamp of the nodes involved in the operation.\n",
    "        # Let's assume for now that `edge_time` are absolute timestamps and we need a reference.\n",
    "        # A common scenario in dynamic graphs is that `x` represents node features at a certain snapshot,\n",
    "        # and `edge_time` are timestamps of interactions (edges).\n",
    "\n",
    "        # The following is a direct interpretation of the user's snippet, \n",
    "        # assuming x has a .time attribute representing current/node timestamps.\n",
    "        # This will likely need adjustment based on the actual data pipeline.\n",
    "        \n",
    "        if hasattr(x, 'time') and x.time is not None:\n",
    "            time_diff = edge_time - x.time # This subtraction might need broadcasting or specific indexing\n",
    "            decay = torch.exp(-self.decay_rate * time_diff.float()) # Ensure float for exp\n",
    "            # Ensure decay has the correct shape for edge_attr, e.g., [num_edges, 1] or [num_edges, num_heads] if per-head decay\n",
    "            if decay.ndim == 1:\n",
    "                decay = decay.unsqueeze(-1)\n",
    "            return super().forward(x, edge_index, edge_attr=decay, size=size)\n",
    "        else:\n",
    "            # Fallback if x.time is not available, call original TGAT\n",
    "            # Or raise an error, or handle differently\n",
    "            print(\"Warning: x.time not available for decay calculation. Using standard TGAT forward.\")\n",
    "            return super().forward(x, edge_index, size=size)\n",
    "\n",
    "# Example Usage (conceptual):\n",
    "# model = TGATWithDecay(in_channels=node_features.size(1), out_channels=32, heads=2, decay_rate=0.05)\n",
    "# node_features_at_t = ... # Node features at current time t (tensor)\n",
    "# node_timestamps_at_t = ... # Node timestamps if they vary per node and are part of input `x`\n",
    "# x_input = (node_features_at_t, node_timestamps_at_t) # Or some object x_input.time = ...\n",
    "# edge_index_at_t = ... # Edge connectivity\n",
    "# edge_timestamps_at_t = ... # Timestamps for each edge\n",
    "\n",
    "# output = model(x_input, edge_index_at_t, edge_timestamps_at_t)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
